[NeuralNetwork]
InputLayer: 2600
HiddenLayer: 2600
OutputLayer: 2600
EncoderActivation: ReLU
DecoderActivation: ReLU
LearningRate: 0.1
LREpochDecay: 300
MaxEpochs: 500
BatchSize: 200
CorruptionFactor: 0.2

[Experiment]
Num: 1
PREFIX: GHT_700
InputFile: 
Output: 
