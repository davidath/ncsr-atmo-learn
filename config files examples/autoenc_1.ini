[NeuralNetwork]
InputLayer: 500
HiddenLayer: 500
OutputLayer: 500
EncoderActivation: ReLU
DecoderActivation: ReLU
LearningRate: 0.1
LREpochDecay: 73
MaxEpochs: 183
BatchSize: 256
CorruptionFactor: 0.2

[Experiment]
Num: 1
PREFIX: MNIST
InputFile: MNIST_hidden.npy
